# Kyle Heppenstall - M4 Portfolio

# Rubric Scores

*   **A: End-of-Module Assessment**: X
*   **B: Individual Work & Projects**: X
*   **C: Group Work & Projects**: X
*   **D: Professional Skills**: X
*   **E: Feedback & Community Participation**: X

-----------------------

# A: End of Module Assessment


# B: Indepenent Work

## [Open Source Contribution](https://gist.github.com/kheppenstall/257c83b82160c312bd89899277c2cc6b)

Blog post links to the criteria. I did 3 bug reports and did not do any documentation since the [shoulda-matchers](https://github.com/thoughtbot/shoulda-matchers) documentation is excellent.

# C: Group Work

## Quantified Self Week 1

On this project I worked with Jesse. We built up our jQuery skills and started testing with javascript for the first time. We became much more familiar with how to organize our javascript code and handle events with javascript.

You will be subjectively graded by an instructor on the following criteria:

### Specification Adherence

- 4: Application implements all functionality as defined, with no bugs, and one extension
- **3: Application implements all functionality as defined, but some bugs or strange behavior where features intersect**
- 2: Application is missing required functionality, deviates significantly from the spec, or serious bugs prevent features from being usable
- 1: Application is missing a significant portion of functionality

### Testing

- **4: All functionality is covered by tests. Appropriate mix of unit and integration tests. Sad path testing in both unit and integration tests.**
- 3: All functionality is covered by tests. Appropriate mix of unit and integration tests.
- 2: More functionality implemented than tested or only uses one test type
- 1: Team fails to effectively test the application.

### HTML/UI

- 4: Team put some effort into styling. HTML features unique IDs, classes and data attributes for DOM traversal.
- **3: Application is not confusing to use. HTML classes and IDs are kebab case.**
- 2: HTML is greatly lacking in standards compliance. UI is confusing or very buggy.
- 1: Application is unusable

### JS syntax and Style

- **4: Javascript features explicit DOM traversal (not using closest), demonstrates great OOP concepts, and uses named and anonymous functions when appropriate**
- 3: Code logically divided into files. Developer can show examples of some SOLID concepts. Attention payed to indentation and naming.
- 2: Javascript is noticeably lacking in the above concepts.
- 1: Team has not applied any style concepts from class or from Ruby background

### Git Workflow

- **4: Team uses master for production, and creates a feature branch for each card worked on. Team is using pull requests with good context and conversation**
- 3: Team is using the feature branches for small groups of cards, and has a pull request for each feature. Developers that aren't on the team have commented on PRs.
- 2: Team fails to use feature branches, or isn't using pull requests
- 1: All code is committed to master

### Project Management

- **4: Team is using a project management tool and updating their progress daily. Team is approving each other's  work. Team is documenting conversations and conclusions on relevant cards.**
- 3: Team is using a project management tool to keep their project organized. Nearly every card has been turned into user stories.
- 2: Team is using a project management tool but didn't update the progress frequently. Many cards have no changes made to them
- 1: Team failed to use a project management tool to track its progress.

### Risk Taking

Adhering to any of these additional specifications will allow you to increase one score above:

- All functionality is part of a class, written using ES6
- No Libraries (except for testing). All JavaScript functionality is your own.

## Quantified Self Week 2

- The documentation for both repos is really thorough! ðŸŽ‰ 
- Lots of small methods.
- Nice separation of responsibility.
- It seems like you both accomplished the goals of CRUD with AJAX so nice work!

## Johari Window (Capstone) -  Sprint One

### 1. Project Management

*   4: Tracker also documents feature related discussions
*   **3: Team is using well formatted user stories and moving cards through each status in realtime**
*   2: Team has used Tracker as a respository of information
*   1: Tracker shows little to no use

### 2. Completion & Pace

*   4: Team is proactive in understanding scope and is able to commit to stories before starting the sprint
*   **3: Team is able to set and update expectations so that there are no surprises on the last day of the sprint**
*   2: Team does not have agreed upon stories completed at the end of the sprint, but has a plan to get them done
*   1: Team does not have agreed upon stories completed, and has no plan to complete them

### 3. Implementation Quality

*   4: Project demonstrates exceptionally well factored code.
*   **3: Project exhibits maintainable well divided code. Developers are able to speak to architecture and implementation decisions.**
*   2: Project demonstrates some gaps in code quality and/or developers cannot defend their decisions.
*   1: Project demonstrates poor factoring and/or understanding of MVC.

### 4. Application of Techniques

*   **4: Project has implemented two or more major techniques that were new this week.**
*   3: Project has implemented one major technique that was new this week.
*   2: Project has a implementation in progress of one major technique that has not been previously attempted.
*   1: Project does not implement new techniques.

### 5. Documentation

*   **4: Project also features a screencast, tutorial or other WOW factor**
*   3: Project features easy to navigate documentation showing how to setup and contribute to the application
*   2: Project features barebones documentation showing how to get the dev environment up and running
*   1: Project has insufficient documentation

### 6. Accessibility

*   4: Team has expertly implemented features to follow accessibility best practices.
*   3: Team has implemented code to increase accessibility.
*   2: Team has considered accessibility issues but has not yet produced code to address them.
*   **1: Team has not considered accessibility issues.**

## Johari Window (Capstone) -  Sprint Two

### 1. Project Management

*   4: Tracker also documents feature related discussions
*   **3: Team is using well formatted user stories and moving cards through each status in realtime**
*   2: Team has used Tracker as a respository of information
*   1: Tracker shows little to no use

### 2. Completion & Pace

*   4: Team is proactive in understanding scope and is able to commit to stories before starting the sprint
*   3: Team is able to set and update expectations so that there are no surprises on the last day of the sprint
*   **2: Team does not have agreed upon stories completed at the end of the sprint, but has a plan to get them done**
*   1: Team does not have agreed upon stories completed, and has no plan to complete them

### 3. Implementation Quality

*   **4: Project demonstrates exceptionally well factored code.**
*   **3: Project exhibits maintainable well divided code. Developers are able to speak to architecture and implementation decisions.**
*   2: Project demonstrates some gaps in code quality and/or developers cannot defend their decisions.
*   1: Project demonstrates poor factoring and/or understanding of MVC.

### 4. Application of Techniques

*   **4: Project has implemented two or more major techniques that were new this week.**
*   3: Project has implemented one major technique that was new this week.
*   2: Project has a implementation in progress of one major technique that has not been previously attempted.
*   1: Project does not implement new techniques.

### 5. Documentation

*   4: Project also features a screencast, tutorial or other wow factor
*   **3: Project features easy to navigate documentation showing how to setup and contribute to the application**
*   **2: Project features barebones documentation showing how to get the dev environment up and running**
*   1: Project has insufficient documentation

### 6. Accessibility

*   4: Team has expertly implemented features to follow accessibility best practices.
*   3: Team has implemented code to increase accessibility.
*   **2: Team has considered accessibility issues but has not yet produced code to address them.**
*   1: Team has not considered accessibility issues.

## Johari Window (Capstone) -  Sprint Three

### 1. Project Management

*   4: Tracker also documents feature related discussions

### 2. Completion & Pace

*   3: Team is able to set and update expectations so that there are no surprises on the last day of the sprint

### 3. Implementation Quality

*   4: Project demonstrates exceptionally well factored code.

### 4. Application of Techniques

*   4: Project has implemented two or more major techniques that were new this week.

### 5. Documentation

*   4: Project also features a screencast, tutorial or other wow factor

### 6. Accessibility

*   4: Team has expertly implemented features to follow accessibility best practices.


## D: Feedback and Community

Co-lead the Automation Gear-Up Session. See [PR](https://github.com/turingschool/gear-up/pull/24).

------------------

## Final Review

### Notes

( Leave blanks for reviewers )

### Outcome

( Leave blanks for reviewers )